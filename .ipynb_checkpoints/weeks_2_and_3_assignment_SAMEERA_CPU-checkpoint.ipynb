{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HlqVBEfLBOF_"
   },
   "source": [
    "**SOW-MKI49: Neural Information Processing Systems**  \n",
    "*Weeks 2 and 3: Assignment (200 points + 20 bonus points + 1 bonus point for each bug you find and another bonus point if you debug it and before you ask, no, typos unfortunately are not considered bugs - first come, first served)*  \n",
    "Author: Umut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rT8BaKk5CpeB"
   },
   "outputs": [],
   "source": [
    "# Group 17: ...\n",
    "# Sameera Sandaruwan - s1014012\n",
    "# Student 2 name, student 2 number: ...\n",
    "# Student 3 name, student 3 number: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Do List\n",
    "1. Finish questions answers - (image resizing function)\n",
    "2. Training problem - resize\n",
    "3. TotalVariation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "00iIAIv37Del"
   },
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "data_directory = 'Data' # Make a directory to store the data and enter it here.\n",
    "                    # We will be using a smaller dataset (LFW) than the one used in the paper (CelebA) for computational resource considerations.\n",
    "                    # Download it from http://vis-www.cs.umass.edu/lfw/lfw-deepfunneled.tgz.\n",
    "device = -1 #sameera GPU - 0\n",
    "epochs = 100 #100\n",
    "lambda_ = {'feature': 1., 'pixel': 1., 'total_variation': 1e-5}\n",
    "model_directory = 'Model' # Make a directory to store the models and enter it here. Move Vgg4Layers.npz to the model directory.\n",
    "outsize = (96, 96)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "86zZctPu1K2M"
   },
   "source": [
    "**Packages (10 points)**  \n",
    "In this cell, you will import the required packages.  \n",
    "*Tasks*   \n",
    "- (1) It is always good practice to first think about the big picture and not rush into writing code before clearly knowing everything that you will have to do so as to avoid future complications. Therefore, your first task is to study the skeleton code and come up with a plan of how to proceed. (**0 points**)\n",
    "- (2) However, I agree that doing so is arguably the most boring part of coding, and you rather skip it. To help you to resist the temptation of skipping going through the skeleton code, I have removed the import statements. Your second task is to Identify the required packages and import them. Note that if you are using Python 2.7, you should import print from the future. (**10 points**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RBiJw5pV030o"
   },
   "outputs": [],
   "source": [
    "# (2) start\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chainer\n",
    "from chainer import Function, gradient_check, report, training, utils, Variable\n",
    "from chainer import datasets, iterators, serializers, dataset\n",
    "from chainer import Link, Chain, ChainList\n",
    "from chainer.optimizers import Adam\n",
    "from chainer.dataset import concat_examples\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer.training import extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JOhjvsOx9lJY"
   },
   "source": [
    "**Preprocessing functions (10 points + 5 bonus points)** (taken from https://github.com/mbeyeler/opencv-python-blueprints)  \n",
    "In the following cell, you will implement some of the preprocessing functions. The rest of the preprocessing steps have already been applied to the data.  \n",
    "*Tasks*\n",
    "- (1) Implement the resizing operation. That is, you should extract the data, resize each portrait to 96 pixels x 96 pixels and save them to the data directory as JPG. (**10 points **)\n",
    "- (2) The pencil sketch class implements the sketch effect in a simpler way than the one mentioned in the lecture. Explain how/why the used operations (blur and divide) convert portraits to sketches, and how it differs from that which was mentioned in the lecture? (**5 bonus points**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iY4lbpLK9kp4"
   },
   "outputs": [],
   "source": [
    "# (1) start\n",
    "# . Get from Jitendra\n",
    "# .\n",
    "# .\n",
    "# (1) end\n",
    "\n",
    "class PencilSketch:\n",
    "    \"\"\"Pencil sketch effect\n",
    "        A class that applies a pencil sketch effect to an image.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, width, height, bg_gray='pencilsketch_bg.jpg'): #ERROR: can't have () here --> def __init__(self, (width, height)):\n",
    "        \"\"\"Initialize parameters\n",
    "            :param (width, height): Image size.\n",
    "        \"\"\"\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "\n",
    "        ### ERROR: useless\n",
    "        # try to open background canvas (if it exists)\n",
    "        self.canvas = cv2.imread(bg_gray, cv2.CV_8UC1)\n",
    "        if self.canvas is not None:\n",
    "            self.canvas = cv2.resize(self.canvas, (self.width, self.height))\n",
    "\n",
    "    def render(self, img_rgb):\n",
    "        \"\"\"Applies pencil sketch effect to an RGB image\n",
    "            :param img_rgb: RGB image to be processed\n",
    "            :returns: Processed RGB image\n",
    "        \"\"\"\n",
    "        img_gray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)\n",
    "        img_blur = cv2.GaussianBlur(img_gray, (21, 21), 0, 0)\n",
    "        img_blend = cv2.divide(img_gray, img_blur, scale=256)\n",
    "\n",
    "        # return cv2.cvtColor(img_blend, cv2.COLOR_GRAY2RGB)\n",
    "        return img_blend\n",
    "\n",
    "def pencil_sketch(img_rgb):\n",
    "    pencilSketch = PencilSketch(img_rgb.shape[1], img_rgb.shape[0])\n",
    "\n",
    "    return pencilSketch.render(img_rgb)\n",
    "\n",
    "# (2) Write your answer here.\n",
    "\n",
    "# chainer conv2d kernal works?\n",
    "\n",
    "#find out what this is\n",
    "def preprocess(img):\n",
    "    if img.mode == 'L':\n",
    "        return np.rollaxis(np.asarray(img, 'float32')[..., None], 2)\n",
    "    else:\n",
    "        return np.rollaxis(np.asarray(img, 'float32')[..., ::-1], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ovQMUuo_7D2k"
   },
   "source": [
    "**Data class**  \n",
    "The following cell defines the data class. It is used to manage the data (loading, etc.). *You do not have to make any changes to the code.*  \n",
    "*Task*\n",
    "- (1) Study the code and refer to the chainer docuimentation if anything is unclear. You will be expected to write similar code by yourself in the coming practicals. (**0 points**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-OF39paH6wff"
   },
   "outputs": [],
   "source": [
    "class Dataset(dataset.DatasetMixin):\n",
    "    def __init__(self, data_files):\n",
    "        self.data_files = data_files\n",
    "\n",
    "    ## ERROR: indentation problem was here\n",
    "    def __len__(self):\n",
    "        return len(self.data_files)\n",
    "\n",
    "    def get_example(self, i):\n",
    "        t = np.asarray(Image.open(self.data_files[i]).convert('RGB').resize((96, 96), Image.LANCZOS), 'f').transpose(2, 0, 1)\n",
    "        x = pencil_sketch(np.asarray(Image.open(self.data_files[i]).convert('RGB').resize((96, 96), Image.LANCZOS), 'f'))[None]\n",
    "        return t, x #t-target (realistic img), x-input(sketch img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iUjEFdDD6xBq"
   },
   "source": [
    "**Model classes (45 points)**  \n",
    "In the following cell you will implement the model classes.\n",
    "*Tasks*   \n",
    "- (1) Implement the layers of the model by filling in the missing code. (**20 points**)\n",
    "- (2) Reimplement the model as a ChainList instead of a Chain. (**5 points**)\n",
    "- (3) Implement the forward pass of the residual block by filling in the missing code. (**20 points**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "### https://docs.chainer.org/en/stable/glance.html\n",
    "### https://docs.chainer.org/en/stable/guides/index.html\n",
    "### https://docs.chainer.org/en/stable/reference/index.html\n",
    "- what are in_channels, out_channels\n",
    "- wht Functions and Links\n",
    "- param of Convolution2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nafY2Wgx6QLt",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Model(Chain):\n",
    "    def __init__(self, in_channels, outsize):\n",
    "        super(Model, self).__init__()\n",
    "        ''' just inicializing different layers (Links [L]) '''\n",
    "        with self.init_scope():\n",
    "            # (1) start\n",
    "            # convolution2D_0 = ...\n",
    "            self.convolution2D_0 = L.Convolution2D(in_channels=in_channels, out_channels=32, \n",
    "                                                   ksize=9, stride=1, pad=4)\n",
    "            # batchNormalization_0 = ...\n",
    "            self.batchNormalization_0 = L.BatchNormalization(32)\n",
    "            # convolution2D_1 = ...\n",
    "            self.convolution2D_1 = L.Convolution2D(in_channels=32, out_channels=64, \n",
    "                                                   ksize=3, stride=2, pad=1)\n",
    "            # batchNormalization_1 = ...\n",
    "            self.batchNormalization_1 = L.BatchNormalization(64)\n",
    "            # convolution2D_2 = ...\n",
    "            self.convolution2D_2 = L.Convolution2D(in_channels=64, out_channels=128, \n",
    "                                                   ksize=3, stride=2, pad=1)\n",
    "            # batchNormalization_2 = ...\n",
    "            self.batchNormalization_2 = L.BatchNormalization(128)\n",
    "        \n",
    "            \n",
    "            # residualBlock_3 = ...\n",
    "            self.residualBlock_3 = ResidualBlock(128, 128)\n",
    "            # residualBlock_4 = ...\n",
    "            self.residualBlock_4 = ResidualBlock(128, 128)\n",
    "            # residualBlock_5 = ...\n",
    "            self.residualBlock_5 = ResidualBlock(128, 128)\n",
    "            # residualBlock_6 = ...\n",
    "            self.residualBlock_6 = ResidualBlock(128, 128)\n",
    "            # residualBlock_7 = ...\n",
    "            self.residualBlock_7 = ResidualBlock(128, 128)\n",
    "            \n",
    "            # deconvolution2D_8 = ...\n",
    "            #self.deconvolution2D_8 = L.Deconvolution2D(in_channels=128, out_channels=64, \n",
    "            #                                           ksize=3, stride=2, pad=1, nobias=True, outsize=outsize)\n",
    "            self.deconvolution2D_8 = L.Deconvolution2D(128, 64, 3, 2, 1, True, outsize=(48, 48))\n",
    "            # batchNormalization_8 = ...\n",
    "            self.batchNormalization_8 = L.BatchNormalization(64)\n",
    "            # (1) end\n",
    "            self.deconvolution2D_9 = L.Deconvolution2D(64, 32, 3, 2, 1, True, outsize=outsize)\n",
    "            self.batchNormalization_9 = L.BatchNormalization(32)\n",
    "            self.convolution2D_10 = L.Convolution2D(32, 3, 9, stride=1, pad=4, nobias = True)\n",
    "            self.batchNormalization_10 = L.BatchNormalization(3)\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.outsize = outsize\n",
    "\n",
    "    def __call__(self, x, finetune = False):\n",
    "        ''' creating the model using the defined \n",
    "        layers and arranging them sequencially. (Functions [F])'''\n",
    "        h = self.convolution2D_0(x)\n",
    "        h = self.batchNormalization_0(h, finetune=finetune)\n",
    "        h = F.relu(h)\n",
    "        h = self.convolution2D_1(h)\n",
    "        h = self.batchNormalization_1(h, finetune=finetune)\n",
    "        h = F.relu(h)\n",
    "        h = self.convolution2D_2(h)\n",
    "        h = self.batchNormalization_2(h, finetune=finetune)\n",
    "        h = F.relu(h)\n",
    "        h = self.residualBlock_3(h, finetune=finetune)\n",
    "        h = self.residualBlock_4(h, finetune=finetune)\n",
    "        h = self.residualBlock_5(h, finetune=finetune)\n",
    "        h = self.residualBlock_6(h, finetune=finetune)\n",
    "        h = self.residualBlock_7(h, finetune=finetune)\n",
    "        h = self.deconvolution2D_8(h)\n",
    "        h = self.batchNormalization_8(h, finetune=finetune)\n",
    "        h = F.relu(h)\n",
    "        h = self.deconvolution2D_9(h)\n",
    "        h = self.batchNormalization_9(h, finetune=finetune)\n",
    "        h = F.relu(h)\n",
    "        h = self.convolution2D_10(h)\n",
    "        h = self.batchNormalization_10(h, finetune=finetune)\n",
    "        y = 127.5 * F.tanh(h) + 127.5 # QQQ: what is this\n",
    "\n",
    "        return y\n",
    "\n",
    "# Another way to define a chain is using the ChainList class, \n",
    "# which behaves like a list of links:\n",
    "class ModelCL(ChainList):\n",
    "    # (2) start\n",
    "    def __init__(self, in_channels, outsize):\n",
    "        # super init is the difference in ChainList\n",
    "        super(ModelCL, self).__init__(\n",
    "            L.Convolution2D(in_channels=in_channels, out_channels=32, ksize=9, stride=1, pad=4),#0\n",
    "            L.BatchNormalization(32),#1\n",
    "            L.Convolution2D(in_channels=32, out_channels=64, ksize=3, stride=2, pad=1),#2\n",
    "            L.BatchNormalization(64),#3\n",
    "            L.Convolution2D(in_channels=64, out_channels=128, ksize=3, stride=2, pad=1),#4\n",
    "            L.BatchNormalization(128),#5\n",
    "            ResidualBlock(128, 128),#6\n",
    "            ResidualBlock(128, 128),#7\n",
    "            ResidualBlock(128, 128),#8\n",
    "            ResidualBlock(128, 128),#9\n",
    "            ResidualBlock(128, 128),#10\n",
    "            L.Deconvolution2D(in_channels=128, out_channels=64, ksize=3, stride=2, pad=1, nobias=True, \n",
    "                              outsize=(48,48)),#11\n",
    "            L.BatchNormalization(64),#12\n",
    "            L.Deconvolution2D(64, 32, 3, 2, 1, True, outsize),#13\n",
    "            L.BatchNormalization(32),#14\n",
    "            L.Convolution2D(32, 3, 9, pad = 4, nobias = True),#15\n",
    "            L.BatchNormalization(3)#16\n",
    "        )\n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        self.outsize = outsize\n",
    "\n",
    "    def __call__(self, x, finetune = False):\n",
    "        ''' creating the model using the defined \n",
    "        layers and arranging them sequencially. (Functions [F])'''\n",
    "        h = self[0](x)\n",
    "        h = self[1](h, finetune)\n",
    "        h = F.relu(h)\n",
    "        h = self[2](h)\n",
    "        h = self[3](h, finetune)\n",
    "        h = F.relu(h)\n",
    "        h = self[4](h)\n",
    "        h = self[5](h, finetune)\n",
    "        h = F.relu(h)\n",
    "        h = self[6](h, finetune)\n",
    "        h = self[7](h, finetune)\n",
    "        h = self[8](h, finetune)\n",
    "        h = self[9](h, finetune)\n",
    "        h = self[10](h, finetune)\n",
    "        h = self[11](h)\n",
    "        h = self[12](h, finetune)\n",
    "        h = F.relu(h)\n",
    "        h = self[13](h)\n",
    "        h = self[14](h, finetune)\n",
    "        h = F.relu(h)\n",
    "        h = self[15](h)\n",
    "        h = self[16](h, finetune)\n",
    "        y = 127.5 * F.tanh(h) + 127.5\n",
    "\n",
    "        return y\n",
    "    # (2) end\n",
    "\n",
    "'''\n",
    "Questions:\n",
    "1. nobias = for neurons no bias variable (b) form (W,b)\n",
    "2. pad ??\n",
    "3. \n",
    "'''    \n",
    "    \n",
    "class ResidualBlock(Chain):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        with self.init_scope():\n",
    "            self.convolution2D_0 = L.Convolution2D( in_channels, out_channels, ksize=3, \n",
    "                                                   stride=1, pad = 1, nobias = True)\n",
    "            self.batchNormalization_0 = L.BatchNormalization(out_channels)\n",
    "            self.convolution2D_1 = L.Convolution2D(out_channels, out_channels, ksize=3, \n",
    "                                                   stride=1, pad = 1, nobias = True)\n",
    "            self.batchNormalization_1 = L.BatchNormalization(out_channels)\n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "    def __call__(self, x, finetune = False):\n",
    "        # (3) start - configuraiton might be different here\n",
    "        h = self.convolution2D_0(x)\n",
    "        h = self.batchNormalization_0(h, finetune=finetune)\n",
    "        h = F.relu(h)\n",
    "        h = self.convolution2D_1(h)\n",
    "        h = self.batchNormalization_1(h, finetune=finetune)\n",
    "        y = h+x # no activation is used; as for the paper\n",
    "        # (3) start\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "euDbOQWT1UA8"
   },
   "source": [
    "**Loss classes (45 points)**  \n",
    "In the following cell, you will implement the loss classes.  \n",
    "*Tasks*  \n",
    "- (1) You are provided with a custom VGG-16 implementation. How does it differ than the original implementation? Why can we get away with using the simpler implementation? (**5 points**)\n",
    "- (2) Implement the missing convolution layer of the total variation loss by filling in the missing code. (**10 points**)\n",
    "- (3) Implement the forward pass of the total variation loss by filling in the missing code. (**10 points**)\n",
    "- (4) Implement the feature loss component in the forward pass of the loss function by filling in the missing code. (**10 points**)\n",
    "- (5) Explain why the loss components are scaled. (**5 points**)\n",
    "- (6) Explain why the target features are extracted in test mode. (**5 points**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9DqHGhS_1M_x"
   },
   "outputs": [],
   "source": [
    "class Vgg4Layers(Chain):\n",
    "    def __init__(self):\n",
    "        super(Vgg4Layers, self).__init__()\n",
    "\n",
    "        with self.init_scope():\n",
    "            self.conv1_1 = L.Convolution2D(  3,  64, 3, pad = 1)\n",
    "            self.conv1_2 = L.Convolution2D( 64,  64, 3, pad = 1)\n",
    "            self.conv2_1 = L.Convolution2D( 64, 128, 3, pad = 1)\n",
    "            self.conv2_2 = L.Convolution2D(128, 128, 3, pad = 1)\n",
    "        #wht is this - adding a persistent value\n",
    "        #Link.add_persistent(self, name='mean', value=np.array([[[[103.939]],[[116.779]],[[ 123.68]]]], dtype='float32'))\n",
    "        #self.mean = np.array([[[[103.939]],[[116.779]],[[ 123.68]]]], dtype='float32')\n",
    "\n",
    "    def __call__(self, x):\n",
    "        #broadcast_to = Broadcast a given variable to a given shape.\n",
    "        h = x - F.broadcast_to(self.mean, x.shape)\n",
    "        h = self.conv1_1(h)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv1_2(h)\n",
    "        h = F.relu(h)\n",
    "        h = F.max_pooling_2d(h, 2, 2)\n",
    "        h = self.conv2_1(h)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2_2(h)\n",
    "        y = F.relu(h)\n",
    "\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Total Variation Loss\n",
    "# 2. feature loss\n",
    "'''\n",
    "How 2x2 kernal convolution produce the total variation loss\n",
    "how kernal values are initialized\n",
    "how does the 2x2 kernal convolution operation accomplish the total variation loss given in the eqn. \n",
    "Does the 2 layer\n",
    "struct. help with that.\n",
    "\n",
    "Convolve input with the kernel [-1; 1] and square\n",
    "Convolve input with the kernel [-1, 1] and square\n",
    "Sum everything and take the square root\n",
    "\n",
    "'''\n",
    "class TotalVariationLoss(Chain):\n",
    "    def __init__(self):\n",
    "        super(TotalVariationLoss, self).__init__()\n",
    "        with self.init_scope():\n",
    "            self.convolution2D_0 = L.Convolution2D(in_channels=3, out_channels=1, ksize=2, nobias=True, \n",
    "                                                   initialW=np.array([3 * [[[-1], [1]]]], 'float32'))\n",
    "            # (2) start\n",
    "            self.convolution2D_1 = L.Convolution2D(in_channels=3, out_channels=1, ksize=2, nobias=True, \n",
    "                                                   initialW=np.array([3 * [[[-1, 1]]]], 'float32'))\n",
    "            # (2) end\n",
    "\n",
    "    def __call__(self, x):\n",
    "        # (3) start\n",
    "        # y = ...\n",
    "        # (3) end\n",
    "        h = self.convolution2D_0(x)\n",
    "        sq1 = np.square(h)\n",
    "        h = self.convolution2D_1(x)\n",
    "        sq2 = np.square(h)\n",
    "        loss_sum = sq1+sq2\n",
    "        y = loss_sum ** 0.5\n",
    "        y = np.sum(y)\n",
    "        \n",
    "        return y\n",
    "\n",
    "    \n",
    "class LossFunction(object):\n",
    "    def __init__(self, lambda_):\n",
    "        self.totalVariationLoss = TotalVariationLoss()\n",
    "        self.vgg4Layers         = Vgg4Layers()\n",
    "\n",
    "    def __call__(self, t, y):            \n",
    "        with chainer.using_config('train', False):\n",
    "            t_ = self.vgg4Layers(t)\n",
    "        # (4) start\n",
    "        # y_ = ...\n",
    "            y_ = self.vgg4Layers(y)\n",
    "        \n",
    "        '''\n",
    "        class chainer.links.VGG16Layers(pretrained_model='auto')\n",
    "        model = chainer.links.VGG16Layers()\n",
    "        t_hat = model.extract(t, layers = [‘conv2_2’], (96, 96))\n",
    "        y_hat = model.extract(y, layers = [‘conv2_2’], (96, 96))\n",
    "        feature_loss = chainer.functions.mean_squared_error(t_hat, y_hat)\n",
    "        '''\n",
    "        \n",
    "        feature_loss = lambda_['feature'] * F.mean_squared_error(t_ , y_)\n",
    "        # (4) end\n",
    "        pixel_loss = lambda_['pixel'] * F.mean_squared_error(t , y)\n",
    "        total_variation_loss = lambda_['total_variation'] * self.totalVariationLoss(y)\n",
    "        loss = feature_loss + pixel_loss + total_variation_loss\n",
    "\n",
    "        return loss\n",
    "\n",
    "# (1) Write your answer here.\n",
    "# (5) Write your answer here.\n",
    "# (6) Write your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_nGcCNEy8p3g"
   },
   "source": [
    "**Initialization (10 points)**  \n",
    "The following cell initializes the loss function, the loss history, the model, the optimizer, the datasets and the iterators. *You do not have to make any changes to the code.*  \n",
    "*Tasks*\n",
    "- (1) Study the code and refer to the chainer docuimentation if anything is unclear. You will be expected to write similar code by yourself in the coming practicals. (**0 points**)  \n",
    "- (2) What are the boolean arguments that are passed to the SerialIterator class? (**5 points**)  \n",
    "- (3) Why is it false for the training iterator but not for other iterators? In other words, what would happen if we were to set it to false for the training iterator and true for the other iterators? (**5 points**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hAa-KI4W-3Mm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13233\n"
     ]
    }
   ],
   "source": [
    "lossFunction = LossFunction(lambda_)\n",
    "serializers.load_npz('{:s}/Vgg4Layers.npz'.format(model_directory), lossFunction.vgg4Layers)\n",
    "'''Question\n",
    "What does mean do??\n",
    "'''\n",
    "lossFunction.vgg4Layers.add_persistent('mean', np.array([[[[103.939]], [[116.779]], [[123.68]]]], 'float32'))\n",
    "\n",
    "loss_history = {'training': [], 'validation': []}\n",
    "model = Model(1, outsize) if device < 0 else Model(1, outsize).to_gpu(device)\n",
    "\n",
    "# Adam parameters\n",
    "# alpha = 0.001/0.0002, beta1= 0.9/0.5, beta2 = 0.999, epsilon = 1/0.1/1e-8\n",
    "\n",
    "\n",
    "optimizer = Adam(alpha=0.001, beta1=0.9, beta2=0.999, eps=1e-08)\n",
    "optimizer.setup(model)\n",
    "\n",
    "\n",
    "import glob\n",
    "data_file = sorted(glob.glob('{}/*/*.jpg'.format(data_directory)))\n",
    "print(len(data_file))\n",
    "\n",
    "train_len = 0.799\n",
    "training_set = Dataset(data_file[:int(train_len * len(data_file))])\n",
    "validation_set = Dataset(data_file[int(train_len * len(data_file)) : int(.8 * len(data_file))])\n",
    "test_set = Dataset(data_file[int(.8 * len(data_file)) :])\n",
    "\n",
    "\n",
    "training_iterator = iterators.SerialIterator(training_set, batch_size, False, True)\n",
    "validation_iterator = iterators.SerialIterator(validation_set, batch_size, False, False)\n",
    "test_iterator = iterators.SerialIterator(test_set , batch_size, False, False)\n",
    "\n",
    "\n",
    "debug_test_set_1 = Dataset(data_file[-4:])\n",
    "debug_test_set_2 = Dataset(data_file[-4:])\n",
    "debug_test_iterator_1 = iterators.SerialIterator(debug_test_set_1 , batch_size, False, False)\n",
    "debug_test_iterator_2 = iterators.SerialIterator(debug_test_set_2 , batch_size, False, False)\n",
    "# (2) Write your answer here.\n",
    "# repeat=False, shuffle=False\n",
    "\n",
    "# (3) Write your answer here.\n",
    "# during the training process, it's batches are selected from a shuffled dataset which makes the training more \n",
    "# generalized. But if we shuffeld the test and validation data, metrics we use to evaluate the model \n",
    "# (accuracy, loss,..) will have much different values due to the shuffel. Hence, using unshuffeled data during test\n",
    "# validation makes it easier to determine that only training will effect the changes in evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 1, 95, 95)\n",
      "(4, 1, 95, 95)\n",
      "---\n",
      "<class 'numpy.ndarray'>\n",
      "(4, 1, 95, 95)\n",
      "<class 'chainer.variable.Variable'>\n",
      "()\n",
      "variable(597145.4)\n",
      "(4, 1, 95, 95)\n",
      "(4, 1, 95, 95)\n",
      "---\n",
      "<class 'numpy.ndarray'>\n",
      "(4, 1, 95, 95)\n",
      "<class 'chainer.variable.Variable'>\n",
      "()\n",
      "variable(615107.6)\n",
      "(4, 1, 95, 95)\n",
      "(4, 1, 95, 95)\n",
      "---\n",
      "<class 'numpy.ndarray'>\n",
      "(4, 1, 95, 95)\n",
      "<class 'chainer.variable.Variable'>\n",
      "()\n",
      "variable(669783.56)\n",
      "(2, 1, 95, 95)\n",
      "(2, 1, 95, 95)\n",
      "---\n",
      "<class 'numpy.ndarray'>\n",
      "(2, 1, 95, 95)\n",
      "<class 'chainer.variable.Variable'>\n",
      "()\n",
      "variable(630671.7)\n"
     ]
    }
   ],
   "source": [
    "aaa_test_set = Dataset(data_file[int(.999 * len(data_file)) :])\n",
    "aaa_iterator = iterators.SerialIterator(aaa_test_set , batch_size, False, True)\n",
    "for j, batch in enumerate(aaa_iterator):\n",
    "    with chainer.using_config('train', True):\n",
    "        t, x = concat_examples(batch=batch, device=device)\n",
    "        y = model(x)\n",
    "        loss = lossFunction(t, y)\n",
    "        print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train | epoch =0 | time=170.46917128562927 sec | loss=456026.4375\n",
      "validation variable(432475.2)\n",
      "validation variable(420631.3)\n",
      "validation variable(464616.16)\n",
      "validation variable(293343.3)\n",
      "validation | epoch =0 | time=83.09318137168884 sec | loss=402766.4921875\n",
      "epoch:   1 / 005, training loss: 456026.4375, validation loss: 402766.4921875.\n",
      "train | epoch =1 | time=196.923424243927 sec | loss=322215.3671875\n",
      "validation variable(424542.78)\n",
      "validation variable(409688.6)\n",
      "validation variable(458491.03)\n",
      "validation variable(289235.12)\n",
      "validation | epoch =1 | time=69.89036130905151 sec | loss=395489.3828125\n",
      "epoch:   2 / 005, training loss: 322215.3671875, validation loss: 395489.3828125.\n",
      "train | epoch =2 | time=171.86837434768677 sec | loss=294491.90625\n",
      "validation variable(429268.97)\n",
      "validation variable(415110.72)\n",
      "validation variable(459646.62)\n",
      "validation variable(283779.75)\n",
      "validation | epoch =2 | time=67.82609534263611 sec | loss=396951.515625\n",
      "epoch:   3 / 005, training loss: 294491.90625, validation loss: 396951.515625.\n",
      "train | epoch =3 | time=196.47498416900635 sec | loss=261264.83203125\n",
      "validation variable(402219.03)\n",
      "validation variable(381555.56)\n",
      "validation variable(422956.53)\n",
      "validation variable(272027.56)\n",
      "validation | epoch =3 | time=75.38920450210571 sec | loss=369689.671875\n",
      "epoch:   4 / 005, training loss: 261264.83203125, validation loss: 369689.671875.\n",
      "train | epoch =4 | time=163.32553791999817 sec | loss=225730.5234375\n",
      "validation variable(510736.34)\n",
      "validation variable(487929.84)\n",
      "validation variable(516817.38)\n",
      "validation variable(416745.03)\n",
      "validation | epoch =4 | time=69.37901544570923 sec | loss=483057.1484375\n",
      "epoch:   5 / 005, training loss: 225730.5234375, validation loss: 483057.1484375.\n"
     ]
    }
   ],
   "source": [
    "# TEST of Training\n",
    "import time\n",
    "\n",
    "for i in range(epochs):#epochs\n",
    "    epoch = i + 1\n",
    "    loss_history['training'].append(0)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for j, batch in enumerate(aaa_iterator):\n",
    "        with chainer.using_config('train', True):\n",
    "            t, x = concat_examples(batch=batch, device=device)\n",
    "            y = model(x)\n",
    "            # (1) start\n",
    "            loss = lossFunction(t, y)\n",
    "            # Calculate the gradients in the network\n",
    "            model.cleargrads()\n",
    "            loss.backward()\n",
    "            # Update all the trainable parameters\n",
    "            optimizer.update()\n",
    "            # (1) end\n",
    "\n",
    "        loss_history['training'][-1] += float(loss.data)\n",
    "        #print('train',loss)\n",
    "\n",
    "    loss_history['training'][-1] /= j + 1\n",
    "    print('train | epoch ={} | time={} sec | loss={}'.format(i, (time.time() - start_time), \n",
    "                                                             loss_history['training'][-1]) )\n",
    "    \n",
    "    # (2) start\n",
    "    loss_history['validation'].append(0)\n",
    "    start_time = time.time()\n",
    "    for j, batch in enumerate(validation_iterator):\n",
    "        with chainer.using_config('train', False):\n",
    "            t, x = concat_examples(batch=batch, device=device)\n",
    "            y = model(x)\n",
    "            loss = lossFunction(t, y)\n",
    "\n",
    "        # ...\n",
    "        loss_history['validation'][-1] += float(loss.data)\n",
    "        #print('validation',loss)\n",
    "\n",
    "    loss_history['validation'][-1] /= j + 1\n",
    "    print('validation | epoch ={} | time={} sec | loss={}'.format(i, (time.time() - start_time), \n",
    "                                                             loss_history['validation'][-1]) )\n",
    "    \n",
    "    # ...\n",
    "    print('epoch: {:3d} / {:03d}, training loss: {}, validation loss: {}.'.format(epoch, epochs, loss_history['training'][-1], loss_history['validation'][-1]))\n",
    "    np.savez('{:s}/loss_history_{:03d}.npz'.format(model_directory, epoch), loss_history)\n",
    "    # (3) start\n",
    "    serializers.save_npz('{:s}/model_{:03d}.npz'.format(model_directory, epoch), model)\n",
    "    # (3) end\n",
    "    serializers.save_npz('{:s}/optimizer_{:03d}.npz'.format(model_directory, epoch), optimizer)\n",
    "    \n",
    "    training_set = Dataset(data_file[:int(train_len * len(data_file))])\n",
    "    validation_set = Dataset(data_file[int(train_len * len(data_file)) : int(.8 * len(data_file))])\n",
    "    test_set = Dataset(data_file[int(.8 * len(data_file)) :])\n",
    "\n",
    "    training_iterator = iterators.SerialIterator(training_set, batch_size, False, True)\n",
    "    validation_iterator = iterators.SerialIterator(validation_set, batch_size, False, False)\n",
    "    test_iterator = iterators.SerialIterator(test_set , batch_size, False, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9db9c70a90>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_history['training'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[456026.4375, 322215.3671875, 294491.90625, 261264.83203125, 225730.5234375]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9dcadad6d8>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_His = np.load('{:s}/loss_history_{:03d}.npz'.format(model_directory, 5))\n",
    "loss_His = loss_His[loss_His.files[0]]\n",
    "loss_His = loss_His.reshape(1,)[0]\n",
    "print(loss_His['training'])\n",
    "\n",
    "plt.plot(loss_His['training'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Model object at 0x7f9dc92c8a20>\n"
     ]
    }
   ],
   "source": [
    "model_ld = Model(1, outsize)\n",
    "serializers.load_npz('{:s}/model_{:03d}.npz'.format(model_directory, 5), model_ld)\n",
    "print(model_ld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_ld = Adam(alpha=0.001, beta1=0.9, beta2=0.999, eps=1e-08)\n",
    "\n",
    "optimizer_ld.setup(model_ld)\n",
    "serializers.load_npz('{:s}/optimizer_{:03d}.npz'.format(model_directory, 5), optimizer_ld)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable(415819.6)\n"
     ]
    }
   ],
   "source": [
    "# trained model\n",
    "for j, batch in enumerate(debug_test_iterator_1):\n",
    "    with chainer.using_config('train', False):\n",
    "        t, x = concat_examples(batch=batch, device=device)\n",
    "        y = model(x)\n",
    "        loss = lossFunction(t, y)\n",
    "        print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable(415819.6)\n"
     ]
    }
   ],
   "source": [
    "# loaded model\n",
    "for j, batch in enumerate(debug_test_iterator_2):\n",
    "    with chainer.using_config('train', False):\n",
    "        t, x = concat_examples(batch=batch, device=device)\n",
    "        y = model_ld(x)\n",
    "        loss = lossFunction(t, y)\n",
    "        print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KAKIEbqPFzsc"
   },
   "source": [
    "**Training and validation (20 points)**  \n",
    "In the following cell, you will train and validate your model.\n",
    "*Tasks*   \n",
    "- (1) Implement training loss estimation, backprop and parameter update. (**10 points**)\n",
    "- (2) Implement validation loss history (**5 points**)\n",
    "- (3) Implement model serialization  (**5 points**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossFunction = LossFunction(lambda_)\n",
    "serializers.load_npz('{:s}/Vgg4Layers.npz'.format(model_directory), lossFunction.vgg4Layers)\n",
    "'''Question\n",
    "What does mean do??\n",
    "'''\n",
    "lossFunction.vgg4Layers.add_persistent('mean', np.array([[[[103.939]], [[116.779]], [[123.68]]]], 'float32'))\n",
    "\n",
    "loss_history = {'training': [], 'validation': []}\n",
    "model = Model(1, outsize) if device < 0 else Model(1, outsize).to_gpu(device)\n",
    "\n",
    "# Adam parameters\n",
    "# alpha = 0.001/0.0002, beta1= 0.9/0.5, beta2 = 0.999, epsilon = 1/0.1/1e-8\n",
    "\n",
    "optimizer = Adam(alpha=0.001, beta1=0.9, beta2=0.999, eps=1e-08)\n",
    "optimizer.setup(model)\n",
    "\n",
    "\n",
    "import glob\n",
    "data_file = sorted(glob.glob('{}/*/*.jpg'.format(data_directory)))\n",
    "print(len(data_file))\n",
    "\n",
    "\n",
    "'''\n",
    "400 imgs - 4 epochs\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "training_set = Dataset(data_file[:399])\n",
    "training_iterator = iterators.SerialIterator(training_set, batch_size, False, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-f0f063852346>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;31m# (1) start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlossFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0;31m# Calculate the gradients in the network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcleargrads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-ddaf9a44d44b>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, t, y)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;31m# (4) end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mpixel_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pixel'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mtotal_variation_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'total_variation'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotalVariationLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpixel_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtotal_variation_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-ddaf9a44d44b>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0msq2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mloss_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msq1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msq2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_sum\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/NIPS/lib/python3.6/site-packages/chainer/functions/math/basic_math.py\u001b[0m in \u001b[0;36mpow\u001b[0;34m(self, rhs)\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mPowVarVar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrhs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0m_check_constant_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrhs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mPowVarConst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrhs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/NIPS/lib/python3.6/site-packages/chainer/function_node.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0;31m# Check for input array types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_arrays_compatible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m             raise TypeError(\n\u001b[1;32m    231\u001b[0m                 \u001b[0;34m'incompatible array types are mixed in the forward input '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/NIPS/lib/python3.6/site-packages/chainer/__init__.py\u001b[0m in \u001b[0;36mis_arrays_compatible\u001b[0;34m(arrays)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0mtypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_cpu_array_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/NIPS/lib/python3.6/site-packages/chainer/__init__.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0mtypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_cpu_array_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Actual of Training\n",
    "import time\n",
    "train_len = 0.79\n",
    "for i in range(epochs):#epochs\n",
    "    epoch = i + 1\n",
    "    loss_history['training'].append(0)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for j, batch in enumerate(training_iterator):\n",
    "        with chainer.using_config('train', True):\n",
    "            t, x = concat_examples(batch=batch, device=device)\n",
    "            y = model(x)\n",
    "            # (1) start\n",
    "            loss = lossFunction(t, y)\n",
    "            # Calculate the gradients in the network\n",
    "            model.cleargrads()\n",
    "            loss.backward()\n",
    "            # Update all the trainable parameters\n",
    "            optimizer.update()\n",
    "            # (1) end\n",
    "\n",
    "        loss_history['training'][-1] += float(loss.data)\n",
    "        print('train=',j,' loss=',loss)\n",
    "\n",
    "    loss_history['training'][-1] /= j + 1\n",
    "    print('train | epoch ={} | time={} sec | loss={}'.format(i, (time.time() - start_time), \n",
    "                                                             loss_history['training'][-1]) )\n",
    "    \n",
    "    # (2) start\n",
    "#     loss_history['validation'].append(0)\n",
    "#     start_time = time.time()\n",
    "#     for j, batch in enumerate(validation_iterator):\n",
    "#         with chainer.using_config('train', False):\n",
    "#             t, x = concat_examples(batch=batch, device=device)\n",
    "#             y = model(x)\n",
    "#             loss = lossFunction(t, y)\n",
    "\n",
    "#         # ...\n",
    "#         loss_history['validation'][-1] += float(loss.data)\n",
    "#         #print('validation',loss)\n",
    "\n",
    "#     loss_history['validation'][-1] /= j + 1\n",
    "#     print('validation | epoch ={} | time={} sec | loss={}'.format(i, (time.time() - start_time), \n",
    "#                                                              loss_history['validation'][-1]) )\n",
    "    loss_history['validation'][-1] = 0.0\n",
    "    # ...\n",
    "    print('epoch: {:3d} / {:03d}, training loss: {}, validation loss: {}.'.format(epoch, epochs, loss_history['training'][-1], loss_history['validation'][-1]))\n",
    "    np.savez('{:s}/loss_history_{:03d}.npz'.format(model_directory, epoch), loss_history)\n",
    "    # (3) start\n",
    "    serializers.save_npz('{:s}/model_{:03d}.npz'.format(model_directory, epoch), model)\n",
    "    # (3) end\n",
    "    serializers.save_npz('{:s}/optimizer_{:03d}.npz'.format(model_directory, epoch), optimizer)\n",
    "    \n",
    "    training_set = Dataset(data_file[:399])\n",
    "    training_iterator = iterators.SerialIterator(training_set, batch_size, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_history['training'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "F-pOSKTw0tcK"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-d2f20054e980>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;31m# Calculate the gradients in the network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcleargrads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0;31m# Update all the trainable parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/NIPS/lib/python3.6/site-packages/chainer/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, retain_grad, enable_double_backprop, loss_scale)\u001b[0m\n\u001b[1;32m    964\u001b[0m         \"\"\"\n\u001b[1;32m    965\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mchainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musing_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'enable_backprop'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menable_double_backprop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backward_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_scale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    967\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_backward_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_scale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/NIPS/lib/python3.6/site-packages/chainer/variable.py\u001b[0m in \u001b[0;36m_backward_main\u001b[0;34m(self, retain_grad, loss_scale)\u001b[0m\n\u001b[1;32m   1093\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m             gxs = func.backward_accumulate(\n\u001b[0;32m-> 1095\u001b[0;31m                 target_input_indexes, out_grad, in_grad)\n\u001b[0m\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgxs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/NIPS/lib/python3.6/site-packages/chainer/function_node.py\u001b[0m in \u001b[0;36mbackward_accumulate\u001b[0;34m(self, target_input_indexes, grad_outputs, grad_inputs)\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;31m# The default implementation uses backward(). You can override this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# method without using backward().\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m         \u001b[0mgxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_input_indexes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[0mlen_gxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "Questions\n",
    "Learn model training in chainer\n",
    "'''\n",
    "for i in range(epochs):\n",
    "    loss_history['training'].append(0)\n",
    "\n",
    "    for j, batch in enumerate(training_iterator):\n",
    "        with chainer.using_config('train', True):\n",
    "            t, x = concat_examples(batch)\n",
    "            y = model(x)\n",
    "            # (1) start\n",
    "            loss = lossFunction(t, y)\n",
    "            # ...\n",
    "            # ...\n",
    "            # ...\n",
    "            # (1) end\n",
    "            # Calculate the gradients in the network\n",
    "            model.cleargrads()\n",
    "            loss.backward()\n",
    "            # Update all the trainable parameters\n",
    "            optimizer.update()\n",
    "\n",
    "        loss_history['training'][-1] += float(loss.data)\n",
    "\n",
    "    loss_history['training'][-1] /= j + 1\n",
    "    # (2) start\n",
    "    # ...\n",
    "    loss_history['validation'].append(0)\n",
    "\n",
    "    for j, batch in enumerate(validation_iterator):\n",
    "        with chainer.using_config('train', False):\n",
    "            t, x = concat_examples(batch)\n",
    "            y = model(x)\n",
    "            loss = lossFunction(t, y)\n",
    "\n",
    "        # ...\n",
    "        loss_history['validation'][-1] += float(loss.data)\n",
    "\n",
    "    loss_history['validation'][-1] /= j + 1\n",
    "    # ...\n",
    "    \n",
    "    \n",
    "    # (2) end\n",
    "    epoch = i + 1\n",
    "    print('epoch: {:3d} / {:03d}, training loss: {:.4f}, validation loss: {:.4f}.'.format(epoch, epochs, loss_history['training'], loss_history['validation']))\n",
    "    np.savez('{:s}/loss_history_{:03d}.npz'.format(model_directory, epoch), loss_history)\n",
    "    # (3) start\n",
    "    serializers.save_npz('{:s}/model_{:03d}.npz'.format(model_directory, epoch), model)\n",
    "    # (3) end\n",
    "    serializers.save_npz('{:s}/optimizer_{:03d}.npz'.format(model_directory, epoch), optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7YivB1PQ7Obh"
   },
   "source": [
    "**Test (45 points + 15 bonus points)**  \n",
    "In the following cell, you will test your model.  \n",
    "*Tasks*\n",
    "- (1) Estimate the test loss, print it and save it. (**15 points**)\n",
    "- (2) Estimate the validation metrics, print them and save them (tip: scikit-image) (**15 bonus points**)\n",
    "- (3) Plot example results (i.e., plot a few t, x and y) (**10 points**)\n",
    "- (4) Dicuss your implementation in 300 - 350 words (e.g., how good your results are, how you can improve your model, etc.) (**20 points**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zdlnCFDS-Cdh"
   },
   "outputs": [],
   "source": [
    "# (1), (2) and (3) start\n",
    "# .\n",
    "# .\n",
    "# .\n",
    "# (1), (2) and (3) end\n",
    "\n",
    "# (4) Write your answer here."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "weeks_2_and_3_assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
